---
title: "(AAAI2019)Diversity-Driven Extensible Hierarchical Reinforcement Learning"
collection: publications
permalink: /publication/AAAI2019
excerpt: 'This paper is about the number 2. The number 3 is left for future work.'
date: 2010-10-01
venue: 'In the proceeding of 33rd AAAI Conference on Artificial Intelligence (AAAI), 2019.***(CCF Rank A, Acceptance rate: 16.2%)***'
paperurl: 'http://academicpages.github.io/files/paper2.pdf'

---
**Authors:** Yuhang Song, Jianyi Wang, Thomas Lukasiewicz, **Zhenghua Xu*** and Mai Xu  
**Abstract:** Hierarchical reinforcement learning (HRL) has recently shown promising advances on speeding up learning, improving the exploration, and discovering intertask transferable skills.MostrecentworksfocusonHRLwithtwolevels,i.e.,a master policy manipulates subpolicies, which in turn manipulate primitive actions. However, HRL with multiple levels is usually needed in many real-world scenarios, whose ultimate goals are highly abstract, while their actions are very primitive. Therefore, in this paper, we propose a diversity-
driven extensible HRL (DEHRL), where an extensible and scalable framework is built and learned levelwise to realize
HRLwithmultiplelevels.DEHRLfollowsapopularassumption: diverse subpolicies are useful, i.e., subpolicies are believed to be more useful if they are more diverse. However, existing implementations of this diversity assumption usually have their own drawbacks, which makes them inapplicable to HRL with multiple levels. Consequently, we further propose a novel diversity-driven solution to achieve this assumption
in DEHRL. Experimental studies evaluate DEHRL with nine baselines from four perspectives in two domains; the results show that DEHRL outperforms the state-of-the-art baselines in all four aspects.

[[Download paper here]](http://academicpages.github.io/files/paper2.pdf)  [[Code Release]](https://github.com/YuhangSong/DEHRL)    [[Oral Presentation]](https://docs.google.com/presentation/d/18olkElCpJoE0iPnyS6DpE8zH8I3mggcCvcWI5yJDJkI/edit#slide=id.p3)
